\documentclass[a4paper, 11pt]{article}

\usepackage[british]{babel}
\usepackage[autostyle]{csquotes}
\usepackage[colorlinks=true, urlcolor=blue, citecolor=blue]{hyperref}

\begin{document}

\title{Forecasting Prices Using Stock Market Index Data}
\author{Student Number: 690065435}
\date{December 2022}
\maketitle

\section{Introduction}
Stock markets from across the world are tracked using indices that measure a section of the stock market, such as the Nasdaq Composite Index. Price forecasting is a very important task in the financial industry, as it can be used to guide strategies.

Historically, financial institutions have used discretionary methods to make investment decisions -- they rely on fundamentals and the judgement of analysts \cite{harvey2017man}. However, with the rise of big data and computational power, systematic methods have become increasingly popular -- institutions use rules-based strategies that are implemented by a computer and involve little to no human intervention \cite{harvey2017man}. Systematic methods enable decisions to be made quickly, which leading market makers and high-frequency trading firms such as Jane Street Capital and Hudson River Trading use to exploit arbitrage opportunities and maximise profits by trading at high volumes \cite{aldridge2013high}. However, these firms do not publicly disclose their strategies, which makes it difficult to understand how they make decisions.

In this project, we will investigate the following question: can we use regression models on stock market index data to forecast prices effectively? My initial hypothesis is that this is not possible as the stock market is a complex system that is difficult to predict. but we will be able to predict general trends.

Previous studies have investigated the prediction of stock market trends with regression on moving averages \cite{dinesh2021prediction}, but they have focused on individual stocks whereas I am focusing on a stock market index. This is a potential snag, as the index is not a direct representation of the stocks it tracks. The efficient market hypothesis also suggests that this will be difficult, as it states that asset prices reflect all available information, yet we would only be predicting according to a subset of information \cite{fama1970efficient}. 

\section{Methodology and Dataset}

\subsection{About Stock Exchange Dataset}
We are using a \href{https://www.kaggle.com/datasets/mattiuzc/stock-exchange-data}{stock exchange dataset on Kaggle} that was collected from Yahoo Finance and contains the daily price data for stock market indices across the world. Each record in the CSV file contains the following information for each trading day:

\begin{itemize}
    \setlength\itemsep{0em}
    \item Index
    \item Date
    \item Opening price
    \item Highest price 
    \item Lowest price 
    \item Closing price adjusted for splits
    \item Adjusted closing price adjusted for both dividends and splits
    \item Volume of shares traded 
\end{itemize}

\subsection{Data Cleaning}
I loaded the CSV file into a pandas dataframe and converted the date to a datetime64 object to make it easier to work with. It originally consisted of 112457 rows. After looking at the information of the data, I noticed that there were 2204 incomplete rows, so I removed them to ensure that the data was consistent. There were also rows with trading volume recorded as 0 in earlier dates where this information was not available, so I removed them to prevent them from skewing the distribution of volume data -- this further reduced the dataset from 110253 rows to 68160 rows.

\subsection{Data Exploration}
The dataset contains a separate CSV file that describes the index information. I loaded this into a pandas dataframe to see the stock exchange that each index corresponds to. Then, I split the data by index, as each index has different characteristics and may behave differently, and calculated the sample size for each index. I decided to focus on the Nasdaq Composite Index (IXIC) as it has the most data points.

Next, I calculated the distribution of features to understand patterns in the data. The distributions of open, high, low, close, and adjusted close are extremely similar, as demonstrated in the histograms -- this makes sense as open, close, and adjusted close are between the low and high for each day.

Meanwhile, the graph of daily volume traded over time shows that market activity has increased over time, which can be attributed to the rise of electronic trading making the stock market more accessible to everyone, including high-frequency trading firms.

I also used Pearson's correlation coefficient to find the correlation between features and the adjusted close price, which is our target variable. As expected, the low, high, and open prices are highly correlated with the adjusted close price because they represent the variance of the index's price over the day. Volume appears to be correlated to adjusted close price, but not as strongly as the other features. However, it is difficult to draw conclusions from this as correlation does not imply causation.

\subsection{Feature Engineering}
The moving average is a data smoothing technique that is used to track price movements by plotting the average prices over a period of time \cite{movingAverageChart}. It helps to  remove noise from random short-term price fluctuations in data to highlight the overall trend direction \cite{movingAverageChart}.

Simple moving averages give equal weight to each point, whereas exponential moving averages give more weight to recent points. Choosing the time period is a trade-off between noise and accuracy -- a longer period will smooth out the data more, but it will also be less accurate. I applied these techniques on each index to show how it works with different price patterns.

\subsection{Data Filtering}
I compared the different methods of calculating moving averages on the IXIC data and found that using exponential moving averages with a time period of 30 days produced the most balanced results. Hence, this will be the input data for the regression models.

\subsection{Data Preprocessing}
I decided to focus on predicting the adjusted close price 30 days in advance, as this would be useful to institutional investors who want to invest part of their monthly paycheck. Thus, I shifted the 30 day exponental average to the future by 30 days to create the input variable, with the adjusted close for that day being the target variable.

Then, I split the data into training and testing sets, with 80\% of the data being used for training and 20\% for testing. The training set will be used train the regression models and the testing set will be used to evaluate their performance.

\subsection{Regression Models}
I will apply three different regression models to generate price predictions and compare their performance.

Ridge regression is a regularised linear regression model that uses L2 regularization to reduce the variance of the model. It is useful for reducing overfitting and improving the generalisation of the model.

LASSO regression is another regularised linear regression model that uses L1 regularization to reduce the variance of the model. It is useful for feature selection, as it can remove features that are not important to the model.

Polynomial regression is a linear regression model that uses polynomial features to fit a non-linear relationship between the input and target variables.


\subsection{Model Evaluation}
For each regression model, I will calculate the $R^2$ score, which is the proportion of the variance in the target variable that is predictable from the input variable. The closer the $R^2$ score is to 1, the better the model is at predicting the target variable. I will also calculate the mean absolute error, which is the average of the absolute differences between the predicted and actual values. The lower the mean absolute error, the better the model is at predicting the target variable. Finally, the root mean squared error is the square root of the mean of the squared differences between the predicted and actual values. The lower the root mean squared error, the better the model is at predicting the target variable.

\section{Results}
\subsection{Ridge Regression}

\subsection{LASSO Regression}

\subsection{Polynomial Regression}

\section{Discussion}

\subsection{Limitations of the Study}
The efficient market hypothesis states that asset prices reflect all available information, which makes it difficult to get arbitrage opportunities. However, Renaissance Technologies, a hedge fund that uses systematic methods, serves as a perfect counter-example -- their Medallion Fund has achieved 66.07\% annualised returns since 1988 \cite{cornell2020medallion}. This suggests that it may be possible to achieve better results given access to big data and computational power, whereas in this study we relied on limited information.

\subsection{Future Work}

\bibliography{main}
\bibliographystyle{ieeetr.bst}

\end{document}